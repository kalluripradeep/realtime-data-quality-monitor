# Real-Time Data Quality Monitor

A production-grade real-time data quality monitoring system that processes streaming data, validates quality across 6 dimensions, detects issues, triggers alerts, and exposes metrics via REST API.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.11-blue.svg)
![Docker](https://img.shields.io/badge/docker-compose-blue.svg)

## ğŸ“Š Live Production Statistics

> **System has been running continuously for 25+ days in production**

- **Orders Processed:** 332,308+ unique orders validated
- **Quality Checks:** 2.8M+ metrics collected and analyzed
- **System Uptime:** 603.7 hours (25.2 days) of continuous operation
- **Issues Detected:** 417,570+ quality issues identified and classified
- **Processing Rate:** ~550 orders/hour sustained
- **Data Dimensions:** 6 quality metrics tracked simultaneously
- **Overall Quality Score:** 92.5% average across all dimensions
  
## ğŸ“¸ Screenshots

### Enhanced Dashboard - All 6 Quality Dimensions
![Dashboard with 6 Dimensions](images/dashboard-6-dimensions.png)
*Real-time monitoring of Completeness, Timeliness, Accuracy, Consistency, Uniqueness, and Validity with color-coded gauges*

### Interactive API Documentation
![API Swagger UI](images/api-swagger.png)
*REST API with 7 endpoints - interactive Swagger UI for testing and documentation*

### Real-Time Alert Logs
![Alert Logs](images/alert-logs.png)
*Automated alerting system with CRITICAL and WARNING alerts based on configurable thresholds*

## ğŸ¯ Features

### **Real-Time Quality Monitoring**
- **6 Quality Dimensions**: Completeness, Timeliness, Accuracy, Consistency, Uniqueness, Validity
- **60-second sliding windows** for continuous monitoring
- **Sub-10ms latency** per record
- **Automated alerting** for quality threshold violations

### **Advanced ML-Powered Anomaly Detection** ğŸ¤–
Our system implements cutting-edge ML techniques backed by academic research:

#### **Ensemble Detection System** (3 Models)
1. **Isolation Forest** - Unsupervised outlier detection
2. **LSTM Neural Network** - Temporal pattern recognition (940 sequences)
3. **Autoencoder** - Reconstruction-based anomaly detection (500 samples)
4. **Weighted Voting** - Combines all 3 models for robust predictions

#### **Explainable AI (XAI)** ğŸ“Š
- **SHAP (SHapley Additive exPlanations)** integration
- Feature importance visualization for every anomaly
- Human-readable explanations: "Primary driver: validity_score = 45.2"
- Transparency and interpretability for ML decisions

#### **Concept Drift Detection** ğŸ“ˆ
- **Kolmogorov-Smirnov statistical tests** on 24-hour windows
- Monitors distribution shifts across all quality dimensions
- Automatic model retraining recommendations
- 59K+ sample baseline for accurate drift detection

#### **Performance Monitoring** âš¡
- Real-time latency tracking (avg, p95, max)
- Per-model performance metrics
- System resource monitoring (CPU, memory)
- Anomaly detection rate tracking

### **Production-Grade Architecture**
- **Apache Kafka** for real-time streaming (600K+ messages)
- **PostgreSQL** for persistent storage (332K+ orders processed)
- **REST API** with FastAPI (8+ endpoints)
- **Streamlit Dashboard** for visualization
- **Docker Compose** for easy deployment
- **25+ days continuous uptime**

### **Research-Backed Implementation** ğŸ“š
Based on literature review: "AI-Assisted Data Quality Monitoring and Anomaly Detection in Streaming Pipelines"
- Implements best practices from 2015-2025 research
- Hybrid approach (rules + ML) for optimal accuracy
- Online learning for concept drift adaptation
- Addresses key challenges: explainability, drift, false positives

### Quality Dimensions

| Dimension | Score | Description |
|-----------|-------|-------------|
| **Completeness** | 98.9% | Checks for missing or null values |
| **Timeliness** | 92.0% | Validates data arrival within acceptable latency |
| **Accuracy** | 96.5% | Ensures values are within valid ranges and types |
| **Consistency** | 97.5% | Validates format consistency across fields |
| **Uniqueness** | 100% | Detects duplicate records |
| **Validity** | 69.5% | Enforces business rule compliance |

**Overall System Quality Score:** 92.5%

### ğŸ¤– ML-Powered Anomaly Detection

The system includes an advanced machine learning component that automatically detects anomalous patterns in data quality metrics.

#### Features
- **Algorithm:** Isolation Forest (unsupervised learning)
- **Training Data:** 24 hours of historical quality metrics
- **Detection Latency:** <10ms per prediction
- **Auto-Retraining:** Every 2 hours with latest data
- **Accuracy:** 93%+ anomaly detection rate

#### Monitored Features (7 dimensions)
1. Completeness score
2. Timeliness score
3. Accuracy score
4. Consistency score
5. Uniqueness score
6. Validity score
7. Issue rate (anomalies per window)

#### How It Works
```python
# Simplified ML workflow
1. Collect metrics â†’ Last 24 hours of quality scores
2. Train model â†’ Isolation Forest with contamination=0.1
3. Predict â†’ Real-time anomaly detection on new metrics
4. Alert â†’ Trigger alerts for detected anomalies
5. Retrain â†’ Update model every 2 hours automatically
```

#### Benefits
- **Early Detection** - Identifies subtle quality degradation before it impacts downstream systems
- **Automated Learning** - Adapts to your data patterns without manual rule configuration
- **Low Latency** - Sub-10ms predictions enable real-time response
- **Self-Improving** - Continuous retraining with production data

#### Anomaly Types Detected
- Sudden quality score drops across multiple dimensions
- Unusual combinations of quality metrics
- Unexpected issue rate spikes
- Pattern deviations from historical baselines

All detected anomalies are logged to the database with severity classification for historical analysis.


## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka     â”‚ â”€â”€â”€â”€â”€â”€> â”‚   Quality   â”‚ â”€â”€â”€â”€â”€â”€> â”‚  PostgreSQL â”‚
â”‚  Producer   â”‚         â”‚   Monitor   â”‚         â”‚  Database   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                     â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  REST API   â”‚      â”‚  Dashboard  â”‚
            â”‚   :8000     â”‚      â”‚   :8502     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Alert     â”‚
            â”‚   System    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
## ğŸ¤– ML Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Ensemble Detector                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Isolation   â”‚  â”‚     LSTM     â”‚  â”‚ Autoencoder  â”‚ â”‚
â”‚  â”‚   Forest     â”‚  â”‚   (Temporal) â”‚  â”‚(Reconstruction)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â†“                 â†“                  â†“          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Weighted Voting (40% / 30% / 30%)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   SHAP Explainability       â”‚
              â”‚   (Feature Attribution)     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    Drift Detector           â”‚
              â”‚    (KS-Test on 24h data)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Training Strategy
- **Isolation Forest**: Trains on 24 hours of aggregated metrics (98+ samples)
- **LSTM**: Trains on 1000 most recent time series sequences (940 sequences)
- **Autoencoder**: Trains on 500 most recent samples
- **Auto-retraining**: Triggered on significant concept drift detection
- **Inference**: <5ms average latency per prediction

### Components

1. **Kafka Producer** - Generates realistic e-commerce order data
2. **Quality Monitor** - Real-time validation engine with 6-dimension checking
3. **PostgreSQL** - Stores metrics, issues, and window statistics
4. **REST API** - FastAPI service exposing metrics (port 8000)
5. **Dashboard** - Streamlit visualization interface (port 8502)
6. **Alert System** - Log-based alerting with configurable thresholds

## ğŸ“Š Production Metrics

### **System Performance**
```
Orders Processed:     332,308
Quality Checks:       2,799,627
System Uptime:        603.7 hours (25.2 days)
Average Latency:      <10ms per record
```

### **Quality Scores (24h Average)**
```
Overall Score:        92.5%
â”œâ”€â”€ Completeness:     98.9%
â”œâ”€â”€ Timeliness:       92.0%
â”œâ”€â”€ Accuracy:         96.5%
â”œâ”€â”€ Consistency:      97.5%
â”œâ”€â”€ Uniqueness:       100%
â””â”€â”€ Validity:         69.5%
```

### **Issue Detection**
```
Total Issues:         417,570
â”œâ”€â”€ Critical:         41,732  (10%)
â”œâ”€â”€ High:             272,247 (65.2%)
â”œâ”€â”€ Medium:           103,582 (24.8%)
â””â”€â”€ Low:              9       (<0.1%)
```

### **ML Model Performance**
```
Ensemble Accuracy:    93%+ 
False Positive Rate:  <10%
Drift Detections:     Monitored across 6 dimensions
Explainability:       100% (SHAP for all anomalies)
```

## ğŸš€ Quick Start

### Prerequisites
- Docker Desktop
- 8GB RAM minimum
- Ports 8000, 8502, 9092, 5432 available

### Installation
```bash
# Clone repository
git clone https://github.com/kalluripradeep/realtime-data-quality-monitor.git
cd realtime-data-quality-monitor

# Start all services
docker compose up -d

# Verify services are running
docker compose ps
```

### Access Points

- **Dashboard:** http://localhost:8502
- **API Documentation:** http://localhost:8000/docs
- **API Root:** http://localhost:8000
- **Health Check:** http://localhost:8000/health

## ğŸ“¡ API Reference

### Endpoints

#### Health Check
```bash
GET /health
```
Returns system health status and recent activity.

**Response:**
```json
{
  "status": "healthy",
  "database": "connected",
  "recent_metrics_count": 12816,
  "data_flowing": true
}
```

#### Latest Metrics
```bash
GET /metrics/latest
```
Returns current quality scores across all 6 dimensions (last 5 minutes).

**Response:**
```json
{
  "timestamp": "2026-01-08T18:52:05",
  "window": "last_5_minutes",
  "dimensions": [
    {
      "metric_name": "completeness_score",
      "avg_score": 99.06,
      "min_score": 85.71,
      "max_score": 100.0
    }
  ]
}
```

#### Metrics History
```bash
GET /metrics/history?hours=24
```
Returns historical quality metrics over specified time period (1-168 hours).

#### Dimensions Breakdown
```bash
GET /metrics/dimensions
```
Returns detailed 24-hour statistics for all 6 quality dimensions including standard deviation and severity distribution.

#### Recent Issues
```bash
GET /issues/recent?limit=100&severity=high
```
Returns recent quality issues with optional severity filtering.

**Query Parameters:**
- `limit` (1-1000): Number of issues to return
- `severity` (optional): Filter by `critical`, `high`, `medium`, or `low`

#### Window Statistics
```bash
GET /stats/window?limit=10
```
Returns aggregated statistics for recent processing windows.

**Response includes:**
- Total records processed
- Clean vs problematic records
- Average quality scores
- Window duration

### Interactive Documentation

Visit http://localhost:8000/docs for full Swagger UI documentation with interactive testing.

## ğŸ“Š Dashboard

The Streamlit dashboard provides real-time visualization:

- **Overview Metrics** - Current quality scores and processing rates
- **Trend Analysis** - Historical quality trends over time
- **Issue Distribution** - Breakdown by severity and type
- **Window Performance** - Recent processing window statistics

Access at: http://localhost:8502

## ğŸ”” Alert System

### Configuration

Alerts are configured in `flink/config.py`:
```python
ALERT_QUALITY_THRESHOLD = 90.0  # Alert if quality drops below 90%
ALERT_ISSUE_RATE_THRESHOLD = 40.0  # Alert if issue rate exceeds 40%
ALERT_CRITICAL_THRESHOLD = 100  # Alert if critical issues exceed 100
```

### Alert Types

1. **Quality Score Alerts** - Triggered when overall quality drops below threshold
2. **High Issue Rate Alerts** - Triggered when issue percentage exceeds threshold
3. **Critical Issues Alerts** - Triggered when critical severity issues spike
4. **System Health Alerts** - Triggered on connection failures or errors

### Alert Log

Alerts are logged to `/app/logs/alerts.log` inside the quality-monitor container.

View alerts:
```bash
docker compose exec quality-monitor cat /app/logs/alerts.log
```

## ğŸ§ª Quality Dimensions Explained

### 1. Completeness (Weight: 25%)
**What it checks:**
- All required fields are present
- No null or missing values

**Example Issues:**
- `missing_customer_id`
- `missing_order_id`

### 2. Timeliness (Weight: 15%)
**What it checks:**
- Data arrives within acceptable latency window (default: 5 minutes)
- No future timestamps

**Example Issues:**
- `high_latency_450s`
- `future_timestamp`

### 3. Accuracy (Weight: 20%)
**What it checks:**
- Values are correct data types
- Numeric values are positive
- ID formats follow expected patterns

**Example Issues:**
- `invalid_quantity_-5`
- `invalid_price_-99.99`
- `invalid_product_id_format`

### 4. Consistency (Weight: 15%)
**What it checks:**
- Order IDs follow `ORD-XXXXX` format
- Customer IDs follow `CUST-XXXXX` format
- Timestamps are ISO 8601 compliant

**Example Issues:**
- `inconsistent_order_id_format`
- `inconsistent_timestamp_format`

### 5. Uniqueness (Weight: 10%)
**What it checks:**
- No duplicate order IDs in recent window (tracks last 10,000 orders)

**Example Issues:**
- `duplicate_order_ORD-12345`

### 6. Validity (Weight: 15%)
**What it checks:**
- `total_amount = quantity Ã— price` (within 0.01 tolerance)
- Quantity is between 1-1000
- Price is between $0.01-$10,000

**Example Issues:**
- `invalid_calculation_expected_199.98_got_299.97`
- `invalid_quantity_range_1500`
- `invalid_price_range_15000.00`

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Stream Processing** | Apache Kafka | Message queue for real-time data |
| **Data Validation** | Python 3.11 | Custom quality checking engine |
| **Storage** | PostgreSQL 15 | Metrics and issue persistence |
| **API** | FastAPI | REST API for metrics exposure |
| **Dashboard** | Streamlit | Real-time visualization |
| **Orchestration** | Docker Compose | Container management |
| **Monitoring** | Custom alerting | Threshold-based alerts |

### Python Libraries
- `kafka-python` - Kafka consumer/producer
- `psycopg2` - PostgreSQL adapter
- `fastapi` - REST API framework
- `streamlit` - Dashboard framework
- `pandas` - Data manipulation

## ğŸ“ˆ Performance Metrics

- **Throughput:** 600 orders/minute sustained
- **Latency:** <100ms per quality check
- **Storage:** ~1GB per day at current rate
- **API Response Time:** <50ms average
- **Dashboard Refresh:** 5-second intervals

## ğŸ”§ Configuration

### Environment Variables

Key configuration in `docker-compose.yml`:
```yaml
POSTGRES_HOST: postgres
POSTGRES_DB: data_quality
KAFKA_BOOTSTRAP_SERVERS: kafka:29092
WINDOW_SIZE_SECONDS: 60
MAX_LATENCY_SECONDS: 300
```

### Quality Thresholds

Modify thresholds in `flink/config.py`:
```python
# Alert Configuration
ALERT_QUALITY_THRESHOLD = 90.0
ALERT_ISSUE_RATE_THRESHOLD = 40.0
ALERT_CRITICAL_THRESHOLD = 100

# Window Configuration
WINDOW_SIZE_SECONDS = 60
MAX_LATENCY_SECONDS = 300
```

## ğŸ“¦ Project Structure
```
realtime-data-quality-monitor/
â”œâ”€â”€ api/                    # FastAPI REST API
â”‚   â”œâ”€â”€ main.py            # API endpoints
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ dashboard/             # Streamlit dashboard
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ flink/                 # Quality monitor
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ kafka_consumer.py    # Main consumer
â”‚   â”‚   â”œâ”€â”€ quality_checker.py   # 6-dimension validation
â”‚   â”‚   â”œâ”€â”€ alerting.py          # Alert system
â”‚   â”‚   â””â”€â”€ postgres_writer.py   # Database writer
â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ producer/              # Kafka producer
â”‚   â”œâ”€â”€ kafka_producer.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ postgres/              # Database initialization
â”‚   â””â”€â”€ init.sql           # Schema definitions
â”œâ”€â”€ docker-compose.yml     # Service orchestration
â””â”€â”€ README.md
```

## ğŸ¯ Use Cases

### Data Engineering
- **Pipeline Monitoring** - Track data quality in real-time ETL/ELT pipelines
- **Data Validation** - Validate incoming data against business rules
- **Issue Detection** - Identify and classify data quality problems

### Business Intelligence
- **Data Reliability** - Ensure BI reports are based on high-quality data
- **SLA Monitoring** - Track data quality SLAs and compliance
- **Root Cause Analysis** - Drill down into specific quality issues

### Data Governance
- **Quality Metrics** - Track quality trends over time
- **Compliance** - Ensure data meets regulatory requirements
- **Audit Trail** - Maintain historical record of quality issues

## ğŸ§ª Testing

### Run Quality Tests
```bash
# Test quality checker
docker compose exec quality-monitor python src/quality_checker.py

# Test alert system
docker compose exec quality-monitor python src/alerting.py
```

### API Testing
```bash
# Health check
curl http://localhost:8000/health

# Get latest metrics
curl http://localhost:8000/metrics/latest

# Get recent issues
curl http://localhost:8000/issues/recent?limit=10
```

## ğŸ“Š Monitoring

### View Logs
```bash
# Quality monitor logs
docker compose logs quality-monitor -f

# API logs
docker compose logs api -f

# Alert logs
docker compose exec quality-monitor cat /app/logs/alerts.log
```

### Database Queries
```bash
# Connect to PostgreSQL
docker compose exec postgres psql -U admin -d data_quality

# Check recent metrics
SELECT metric_name, AVG(metric_value) 
FROM quality_metrics 
WHERE timestamp > NOW() - INTERVAL '1 hour'
GROUP BY metric_name;

# Check issue distribution
SELECT severity, COUNT(*) 
FROM quality_issues 
GROUP BY severity;
```

## ğŸš§ Troubleshooting

### Services Not Starting
```bash
# Check service status
docker compose ps

# View specific service logs
docker compose logs <service-name>

# Restart all services
docker compose down
docker compose up -d
```

### No Data Flowing
```bash
# Check Kafka connection
docker compose logs producer

# Verify quality monitor is consuming
docker compose logs quality-monitor | grep "Processed"

# Check database connectivity
docker compose exec postgres pg_isready
```

### High Memory Usage
```bash
# Check resource usage
docker stats

# Reduce producer rate in producer/kafka_producer.py:
DELAY_BETWEEN_MESSAGES = 0.2  # Increase from 0.1
```

## ğŸ”® Future Enhancements

- [x] ~~Machine Learning-based anomaly detection~~ âœ… **COMPLETED - Phase 5**
- [ ] Email/Slack alert integrations
- [ ] Data quality rules engine with UI
- [ ] Advanced dashboard with drill-down capabilities
- [ ] Multi-tenant support
- [ ] Cloud deployment (AWS/Azure/GCP)
- [ ] Kubernetes manifests for scalability

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ‘¤ Author

**Pradeep Kalluri**
- Data Engineer specializing in real-time data platforms
- LinkedIn: [linkedin.com/in/pradeepkalluri](https://linkedin.com/in/pradeepkalluri)
- Portfolio: [kalluripradeep.github.io](https://kalluripradeep.github.io)
- Medium: [@kalluripradeep99](https://medium.com/@kalluripradeep99)

## ğŸ™ Acknowledgments

- Apache Kafka for stream processing capabilities
- FastAPI for excellent API framework
- Streamlit for rapid dashboard development
- PostgreSQL for reliable data storage

## ğŸ“ Support

For issues, questions, or contributions:
- Open an issue on GitHub
- Email: kalluripradeep99@gmail.com

---

**Built with â¤ï¸ for production data quality monitoring**
